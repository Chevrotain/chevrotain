(window.webpackJsonp=window.webpackJsonp||[]).push([[48],{490:function(e,t,a){"use strict";a.r(t);var n=a(55),r=Object(n.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"tutorial-fault-tolerant"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tutorial-fault-tolerant"}},[e._v("#")]),e._v(" Tutorial - Fault Tolerant")]),e._v(" "),a("h3",{attrs:{id:"tldr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tldr"}},[e._v("#")]),e._v(" TLDR")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/SAP/chevrotain/tree/master/examples/tutorial/step4_error_recovery",target:"_blank",rel:"noopener noreferrer"}},[e._v("Run and Debug the source code"),a("OutboundLink")],1),e._v(".")]),e._v(" "),a("h2",{attrs:{id:"introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),a("p",[e._v("In the previous tutorial steps we have learned how to build a parser for a simple grammar.\nOur parser can handle valid inputs just fine, but what happens if the input is not perfectly valid?\nFor example when building an editor for a programing language, the input is often not completely valid,\nyet the editor is still expected to provide functionality (outline/auto-complete/navigation/error locations...)\neven for invalid inputs.")]),e._v(" "),a("p",[e._v("Chevrotain uses several fault tolerance / error recovery heuristics, which generally follow error recovery heuristics\nused in Antlr3.")]),e._v(" "),a("h2",{attrs:{id:"single-token-insertion"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#single-token-insertion"}},[e._v("#")]),e._v(" Single Token insertion")]),e._v(" "),a("p",[e._v("Happens when:")]),e._v(" "),a("ul",[a("li",[e._v("A token Y is expected.")]),e._v(" "),a("li",[e._v("But a token X is found.")]),e._v(" "),a("li",[e._v("X is a valid token after the missing Y token.")])]),e._v(" "),a("p",[e._v("A Y token will be automatically "),a("strong",[e._v("inserted")]),e._v(" into the token stream.")]),e._v(" "),a("p",[e._v("For example: in a JSON Grammar colons are used between keys and values.")]),e._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("// GOOD")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key"')]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("666")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("// BAD, missing colon")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key"')]),e._v("   "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("666")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n")])])]),a("p",[e._v('If we try parsing the "bad" example, after consuming:')]),e._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key"')]),e._v("\n")])])]),a("ul",[a("li",[e._v("We expect a colon token (Y).")]),e._v(" "),a("li",[e._v("We will find a number(666) token (X) in the remaining text: '666 }'.")]),e._v(" "),a("li",[e._v("After the colon token, a number token is valid.")])]),e._v(" "),a("p",[e._v('Therefore the missing colon will be automatically "inserted".')]),e._v(" "),a("p",[e._v("This heuristic's behavior can be customized by the following methods:")]),e._v(" "),a("ul",[a("li",[a("p",[a("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/7_0_2/classes/cstparser.html#cantokentypebeinsertedinrecovery",target:"_blank",rel:"noopener noreferrer"}},[e._v("canTokenTypeBeInsertedInRecovery"),a("OutboundLink")],1)])]),e._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/7_0_2/classes/cstparser.html#gettokentoinsert",target:"_blank",rel:"noopener noreferrer"}},[e._v("getTokenToInsert"),a("OutboundLink")],1)])])]),e._v(" "),a("h2",{attrs:{id:"single-token-deletion"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#single-token-deletion"}},[e._v("#")]),e._v(" Single Token deletion:")]),e._v(" "),a("p",[e._v("Happens when:")]),e._v(" "),a("ul",[a("li",[e._v("A token Y is expected.")]),e._v(" "),a("li",[e._v("But a token X is found.")]),e._v(" "),a("li",[e._v("And immediately after X an Y is found.")])]),e._v(" "),a("p",[e._v("The unexpected token X will be skipped ("),a("strong",[e._v("deleted")]),e._v(") and the parsing will continue.")]),e._v(" "),a("p",[e._v("For example: lets look at the case of a")]),e._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("// GOOD")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key"')]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("666")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v('// BAD, redundant "}"')]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key"')]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("666")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n")])])]),a("p",[e._v('If we try parsing the "bad" example, after consuming:')]),e._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key"')]),e._v("\n")])])]),a("ul",[a("li",[e._v("We are expecting a colon token (Y).")]),e._v(" "),a("li",[e._v("But we found right brackets (X) instead.")]),e._v(" "),a("li",[e._v('The next token ("ðŸ˜Š is a colon token (Y) which the one we originally expected.')])]),e._v(" "),a("p",[e._v('Therefore the redundant right brackets "}" will be skipped (deleted) and the parser will consume the number token.')]),e._v(" "),a("h2",{attrs:{id:"re-sync-recovery"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#re-sync-recovery"}},[e._v("#")]),e._v(" Re-Sync Recovery")]),e._v(" "),a("p",[e._v("The following re-sync recovery examples use this sample json like grammar:")]),e._v(" "),a("div",{staticClass:"language-ANTLR extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('object\n   : "{" objectItem (comma objectItem)* "}"\n\nobjectItem\n   : stringLiteral ":" value\n\nvalue\n   : object | stringLiteral | number | ...\n')])])]),a("h2",{attrs:{id:"repetition-re-sync"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#repetition-re-sync"}},[e._v("#")]),e._v(" Repetition Re-Sync")]),e._v(" "),a("p",[e._v("Repetition re-sync recovery happens when:")]),e._v(" "),a("ul",[a("li",[e._v("The parser is in a repetition(MANY/AT_LEAST_ONE/MANY_SEP/AT_LEAST_ONE_SEP).")]),e._v(" "),a("li",[e._v('The parser has consumed the last iteration and is about to "exit" the repetition.')]),e._v(" "),a("li",[e._v("The next token X is invalid right after the repetition ended.")])]),e._v(" "),a("p",[e._v("In such a situation the parser will attempt to skip tokens until it detects the beginning of a another iteration of\nthe repetition "),a("strong",[e._v("or")]),e._v(" the token it originally expected after the last iteration.")]),e._v(" "),a("p",[e._v("There are a couple of edge cases in which "),a("strong",[e._v("other")]),e._v(" recovery methods will be preferred:")]),e._v(" "),a("ul",[a("li",[e._v("If single token insertion/deletion can be performed, it is always preferred as it skips fewer tokens.")]),e._v(" "),a("li",[e._v("If between rules re-sync recovery can be performed (see below) "),a("strong",[e._v("and")]),e._v(" it can be done by skipping "),a("strong",[e._v("fewer")]),e._v(' tokens.\nBetween rules re-sync will be preferred over repetition re-sync recovery. The same principle applies, the heuristics are greedy\nand "prefer" to skip the fewest number of tokens.')])]),e._v(" "),a("p",[e._v("Example:")]),e._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("\n  "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key1"')]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("\n  "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key2"')]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("666")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("// '666' should not appear here!")]),e._v('\n  "key3  '),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v('\n  "key4  '),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("4")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n")])])]),a("p",[e._v("If we try parsing this input example, after consuming:")]),e._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("\n  "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key1"')]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("\n  "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"key2"')]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("2")]),e._v("\n")])])]),a("ul",[a("li",[e._v("The parser in in a repetition of **(comma objectItem)* **")]),e._v(" "),a("li",[e._v('After consuming \'"key2" : 2\' the parser "thinks" it has consumed the last iteration as the next comma is missing.')]),e._v(" "),a("li",[e._v('The next token (X) encountered is "666" which is invalid in that position as the parser expected a "}" after the repetition ends.')]),e._v(" "),a("li",[e._v('The parser will throw away the following tokens [666, "key3", :, 3] and re-sync to the next comma (,) to continue a another iteration.')])]),e._v(" "),a("p",[e._v("Note that in such a situation some input would be lost, (the third key), however the fourth key will still be parsed successfully!")]),e._v(" "),a("h2",{attrs:{id:"general-re-sync"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#general-re-sync"}},[e._v("#")]),e._v(" General Re-Sync")]),e._v(" "),a("p",[e._v("General re-sync recovery happens when the parser encounters a parser error inside a rule which\nit cannot recover from in other ways.\nFor example:")]),e._v(" "),a("ul",[a("li",[e._v("An unexpected Token as been found (MisMatchTokenException) but single token insertion/deletion cannot resolve it.")]),e._v(" "),a("li",[e._v("None of the alternatives in an OR match.")]),e._v(" "),a("li",[e._v("A Repetition of AT_LEAST_ONE cannot match even one iteration.")]),e._v(" "),a("li",[e._v("...")])]),e._v(" "),a("p",[e._v("In re-sync recovery the parser will skip tokens from the token stream until it detects a point it can continue parsing from.\nThe parser will try to skip as few tokens as possible and re-sync to the closest rule in the rule stack.")]),e._v(" "),a("p",[a("strong",[e._v("An Abstract example:")])]),e._v(" "),a("ul",[a("li",[e._v("Grammar Rule A called Grammar Rule B which called Grammar Rule C (A -> B -> C).")]),e._v(" "),a("li",[e._v("In Grammar Rule C a parsing error happened which we can not recover from.")]),e._v(" "),a("li",[e._v("The Parser will now skip tokens until it find a token that can appear immediately after either:\n"),a("ul",[a("li",[e._v("The call of C in B")]),e._v(" "),a("li",[e._v("The call of B in A")])])])]),e._v(" "),a("p",[a("strong",[e._v("A concrete example:")])]),e._v(" "),a("p",[e._v("For the following invalid json input:")]),e._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("\n\t"),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"firstName"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"John"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("\n\t"),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"someData"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v("\n\t   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"bad"')]),e._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"part"')]),e._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("// <-- too many colons in the nested object")]),e._v("\n\t"),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"isAlive"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[e._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("\n\t"),a("span",{pre:!0,attrs:{class:"token string"}},[e._v('"age"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v(":")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[e._v("25")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n")])])]),a("ul",[a("li",[a("p",[e._v("When encountering the the redundant colon the rule stack will be as follows:")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("object")]),e._v(" --\x3e top level object")]),e._v(" "),a("li",[a("strong",[e._v("objectItem")]),e._v(' --\x3e "someData": ... - second item in the top level object')]),e._v(" "),a("li",[a("strong",[e._v("value")]),e._v(' --\x3e { "bad" :: "part" } - the value of the "someData" key')]),e._v(" "),a("li",[a("strong",[e._v("object")]),e._v(' --\x3e { "bad" :: "part" } - the value of the "someData" key')]),e._v(" "),a("li",[a("strong",[e._v("objectItem")]),e._v(' --\x3e "bad" :: "part" - the single item in the inner object.')]),e._v(" "),a("li",[a("strong",[e._v("value")]),e._v(' --\x3e : "part" - the value with the colon prefix')])])]),e._v(" "),a("li",[a("p",[e._v("The redundant colon will cause an error (NoViableAltException) as the value rule will not be able to decide\nwhich alternative to take as none would match.")])]),e._v(" "),a("li",[a("p",[e._v("This means the parser needs to find a token to synchronize to, lets check the options:")]),e._v(" "),a("ul",[a("li",[e._v("After value called by ObjectItem --\x3e none")]),e._v(" "),a("li",[e._v("After objectItem called by object --\x3e comma.")]),e._v(" "),a("li",[e._v("After object called by value --\x3e none.")]),e._v(" "),a("li",[e._v("After value called by ObjectItem --\x3e none")]),e._v(" "),a("li",[e._v("after objectItem called by object --\x3e comma (again).")])])]),e._v(" "),a("li",[a("p",[e._v("so the Parser will re-sync to the closest ObjectItem if it finds a comma in the remaining token stream.")])]),e._v(" "),a("li",[a("p",[e._v("Therefore the following tokens will be skipped: [':', '\"part\"', '}']")])]),e._v(" "),a("li",[a("p",[e._v('And the Parser continue from the "nearest" objectItem rule as if it was successfully invoked.')])]),e._v(" "),a("li",[a("p",[e._v("Thus the next two items will appear be parsed successfully even though they were preceded by a syntax error!")])])]),e._v(" "),a("h2",{attrs:{id:"enabling"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#enabling"}},[e._v("#")]),e._v(" Enabling")]),e._v(" "),a("p",[e._v("By default fault tolerance and error recovery heuristics are "),a("strong",[e._v("disabled")]),e._v(".\nThey can be enabled by passing a optional "),a("strong",[e._v("recoveryEnabled")]),e._v(" parameter (default true)\nTo the parser's constructor "),a("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/7_0_2/classes/cstparser.html#constructor",target:"_blank",rel:"noopener noreferrer"}},[e._v("constructor"),a("OutboundLink")],1),e._v(".")]),e._v(" "),a("p",[e._v("Once enabled specific rules may have their re-sync recovery disabled explicitly,\nThis is can be done during the definition of the grammar rule "),a("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/7_0_2/classes/cstparser.html#rule",target:"_blank",rel:"noopener noreferrer"}},[e._v("RULE"),a("OutboundLink")],1),e._v(".\nThe third parameter("),a("strong",[e._v("config")]),e._v(") may contain a "),a("strong",[e._v("resyncEnabled")]),e._v(" property that controls whether or not re-sync is enabled for the\n"),a("strong",[e._v("specific")]),e._v(" rule.")]),e._v(" "),a("h2",{attrs:{id:"cst-integration"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cst-integration"}},[e._v("#")]),e._v(" CST Integration")]),e._v(" "),a("p",[e._v("When using "),a("RouterLink",{attrs:{to:"/guide/concrete_syntax_tree.html"}},[e._v("Concrete Syntax Tree")]),e._v(" output\nA re-synced will return a CSTNode with the boolean "),a("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/7_0_2/interfaces/cstnode.html#recoverednode",target:"_blank",rel:"noopener noreferrer"}},[e._v('"recoveredNode"'),a("OutboundLink")],1),e._v(" flag marked as true.\nAdditionally a recovered node "),a("strong",[e._v("may not")]),e._v(" have all its contents (children dictionary) filled\nas only the Terminals and None-Terminals encountered "),a("strong",[e._v("before")]),e._v(" the error which triggered the re-sync\nwill be present. This means that code that handles the CST (CST Walker or Visitor) "),a("strong",[e._v("must not")]),e._v("\nassume certain content is always present on a CstNode. Instead it must be very defensive to avoid runtime\nerrors.")],1),e._v(" "),a("h2",{attrs:{id:"embedded-actions-integration"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#embedded-actions-integration"}},[e._v("#")]),e._v(" Embedded Actions Integration")]),e._v(" "),a("p",[e._v('Just being able to continue parsing is not enough, as "someone" probably expects a returned value\nfrom the sub-rule we have recovered from.')]),e._v(" "),a("p",[e._v("By default "),a("strong",[e._v("undefined")]),e._v(" will be returned from a recovered rule, however this should most likely be customize\nin any but the most simple cases.")]),e._v(" "),a("p",[e._v("Customization is done during the definition of the grammar "),a("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/7_0_2/classes/cstparser.html#rule",target:"_blank",rel:"noopener noreferrer"}},[e._v("RULE"),a("OutboundLink")],1),e._v(".\nThe third parameter("),a("strong",[e._v("config")]),e._v(") may contain a "),a("strong",[e._v("recoveryValueFunc")]),e._v(" property which is a function that will be invoked to produce the returned value in\ncase of re-sync recovery.")]),e._v(" "),a("h2",{attrs:{id:"types-of-recovery-strategies"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#types-of-recovery-strategies"}},[e._v("#")]),e._v(" Types Of Recovery Strategies")]),e._v(" "),a("ul",[a("li",[e._v('Single Token insertion/deletion and repetition re-sync are "in rule" recovery strategies.')]),e._v(" "),a("li",[e._v('General re-sync Recovery is a "between rules" recovery strategy.')])]),e._v(" "),a("p",[e._v("The main difference is that \"in-rule\" recovery fixes the problem in the scope of a single rule\nwithout changes to the parser's rule stack and the parser's output will still be valid.")]),e._v(" "),a("p",[e._v('But "Between Rules" recovery will fail at least one parsing rule (and perhaps many more).\nThus the latter tends to "lose" more of the original input, may\npotentially causes invalid output structure (e.g: partial CST structure)\nand require additional definitions (e.g: what should be returned value of a re-synced rule?).')])])}),[],!1,null,null,null);t.default=r.exports}}]);