(window.webpackJsonp=window.webpackJsonp||[]).push([[35],{202:function(t,e,s){"use strict";s.r(e);var a=s(0),n=Object(a.a)({},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"content"},[t._m(0),t._v(" "),t._m(1),t._v(" "),t._m(2),t._v(" "),t._m(3),t._v(" "),t._m(4),t._v(" "),s("p",[t._v("A Chevrotain Lexer will by default track the full position information for each token.\nThis includes line and column information.")]),t._v(" "),s("p",[t._v("In order to support this the Lexer must be aware of which Tokens may include line terminators.\nNormally this information can be computed automatically however in some cases Chevrotain needs some hints.")]),t._v(" "),s("p",[t._v("This warning means that the Lexer has been defined to track line and column information (perhaps by default).\nYet not a single one of the Token definitions passed to it was detected as possibly containing line terminators.")]),t._v(" "),s("p",[t._v("To resolve this choose one of the following:")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("Disable the line and column position tracking using the "),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/4_6_0/interfaces/ilexerconfig.html#positiontracking",target:"_blank",rel:"noopener noreferrer"}},[t._v("positionTracking"),s("OutboundLink")],1),t._v(" configuration option.")]),t._v(" "),t._m(5)]),t._v(" "),s("li",[s("p",[t._v("Mark the Tokens which may include a line terminator with an explicit line_breaks flag.")]),t._v(" "),t._m(6),s("ul",[s("li",[s("p",[t._v("Note that the definition of what constitutes a line terminator is controlled by the\n"),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/4_6_0/interfaces/ilexerconfig.html#lineTerminatorsPattern",target:"_blank",rel:"noopener noreferrer"}},[t._v("lineTerminatorsPattern"),s("OutboundLink")],1),t._v(" lexer configuration property.")])]),t._v(" "),t._m(7)])])]),t._v(" "),t._m(8),t._v(" "),s("p",[t._v("A Chevrotain lexer must be aware which of the Token Types may match a line terminator.\nThis is required to compute the correct line and column position information.\nNormally Chevrotain can identify this information automatically using the "),s("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast library"),s("OutboundLink")],1),t._v(",\nhowever sometimes this logic fails. This is only a "),s("strong",[t._v("warning")]),t._v(" which will cause a small performance\nloss to the lexer and would "),s("strong",[t._v("not")]),t._v(" impact its correctness.")]),t._v(" "),t._m(9),t._v(" "),t._m(10),s("p",[t._v("Also please open an issue in the "),s("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast library"),s("OutboundLink")],1),t._v("\nso the the root problem could be tracked and resolved.")]),t._v(" "),t._m(11),t._v(" "),s("p",[t._v("A Chevrotain lexer must be aware which of the Token Types may match a line terminator.\nIt is not possible to do so automatically when using "),s("a",{attrs:{href:"https://sap.github.io/chevrotain/docs/guide/custom_token_patterns.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("custom token patterns"),s("OutboundLink")],1),t._v(".\nThis means it is highly recommended to explicitly provide the line_breaks argument when creating\na TokenType:")]),t._v(" "),t._m(12),s("p",[t._v("This is only a "),s("strong",[t._v("warning")]),t._v(' which will cause a small performance\nloss to the lexer and would not impact its correctness.\nIf no explicit <line_break> option is provided it would be implicitly treated as "true"\nfor '),s("a",{attrs:{href:"https://sap.github.io/chevrotain/docs/guide/custom_token_patterns.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("custom token patterns"),s("OutboundLink")],1),t._v(".")]),t._v(" "),t._m(13),t._v(" "),s("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matches\nusing the next "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode"),s("OutboundLink")],1),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),s("strong",[t._v("every")]),t._v(" Token Type must be identified.")]),t._v(" "),s("p",[t._v("This analysis is implemented using the "),s("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast"),s("OutboundLink")],1),t._v(" library.\nWhich means this "),s("strong",[t._v("warning")]),t._v(" usually indicates a bug in the regexp-to-ast library.\nThe impact is only that the optimization described above would become disabled.\nLexing and Parsing will still work correctly, only slower...")]),t._v(" "),s("p",[t._v("Please open a bug for the "),s("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast"),s("OutboundLink")],1),t._v(" library.\nThis issue can be "),s("strong",[t._v("worked around")]),t._v(' by explicitly providing a "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/4_6_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),s("OutboundLink")],1),t._v('" property.')]),t._v(" "),t._m(14),t._m(15),t._v(" "),s("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matchs\nusing the next "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode"),s("OutboundLink")],1),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),s("strong",[t._v("every")]),t._v(" TokenType must be identified.")]),t._v(" "),s("p",[t._v("This analysis is implemented using the "),s("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast"),s("OutboundLink")],1),t._v(" library.\nThis library currently does not support the "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/unicode",target:"_blank",rel:"noopener noreferrer"}},[t._v("unicode regexp flag"),s("OutboundLink")],1),t._v("\nThe impact is that the optimization described above would become disabled.\nLexing and Parsing will still work correctly, just slower...")]),t._v(" "),s("p",[t._v("This issue can be "),s("strong",[t._v("worked around")]),t._v(' by explicitly providing a "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/4_6_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),s("OutboundLink")],1),t._v('" property.')]),t._v(" "),t._m(16),t._m(17),t._v(" "),t._m(18),t._m(19),t._v(" "),s("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matchs\nusing the next "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode"),s("OutboundLink")],1),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),s("strong",[t._v("every")]),t._v(" TokenType must be identified.")]),t._v(" "),t._m(20),t._v(" "),t._m(21),t._v(" "),t._m(22),t._m(23),t._v(" "),s("p",[t._v('If the use of these optimizations is desired and the startup resources cost is acceptable\nIt is possilbe to enable the optimizations by explicitly providing a "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/4_6_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),s("OutboundLink")],1),t._v('" property.\ne.g:')]),t._v(" "),t._m(24),s("p",[t._v("Please Note that filling such an array "),s("a",{attrs:{href:"https://jsperf.com/fill-16-bits",target:"_blank",rel:"noopener noreferrer"}},[t._v("can take over 1ms"),s("OutboundLink")],1),t._v(" on a modern machine.\nSo if you are only parsing small inputs and/or starting a new process for each\nparser invocation the added initilization cost may be counter productive.")]),t._v(" "),t._m(25),t._v(" "),t._m(26),t._v(" "),s("p",[t._v("A Token RegExp pattern used in a chevrotain lexer may not use the start/end of input anchors ('$' and '^').")]),t._v(" "),t._m(27),s("p",[t._v("To resolve this simply avoid using anchors in your Token Types patterns.")]),t._v(" "),t._m(28),t._v(" "),t._m(29),t._v(" "),s("p",[t._v("For example:")]),t._v(" "),t._m(30),t._m(31),t._v(" "),s("p",[t._v("To resolve this simply re-arrange the order of Token types in the lexer\ndefinition such that the more specific Token types will be listed first.")]),t._v(" "),t._m(32),t._m(33),t._v(" "),t._m(34),s("p",[t._v("To resolve this second problem see how to prefer the "),s("strong",[t._v("longest match")]),t._v("\nas demonstrated in the "),s("a",{attrs:{href:"https://github.com/SAP/Chevrotain/blob/master/examples/lexer/keywords_vs_identifiers/keywords_vs_identifiers.js",target:"_blank",rel:"noopener noreferrer"}},[t._v("keywords vs identifiers example"),s("OutboundLink")],1)]),t._v(" "),t._m(35),t._v(" "),s("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matchs\nusing the next "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode"),s("OutboundLink")],1),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),s("strong",[t._v("every")]),t._v(" TokenType must be identified.")]),t._v(" "),s("p",[t._v("This information cannot be automatically computed for "),s("a",{attrs:{href:"https://sap.github.io/chevrotain/docs/guide/custom_token_patterns.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("custom token patterns"),s("OutboundLink")],1),t._v("\nand "),s("strong",[t._v("should")]),t._v(' therefore be explicitly provided using the "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/4_6_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),s("OutboundLink")],1),t._v('" property.')]),t._v(" "),s("p",[t._v("For example:")]),t._v(" "),t._m(36),s("p",[t._v('Providing the "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/4_6_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),s("OutboundLink")],1),t._v('" property is '),s("strong",[t._v("not")]),t._v(" mandatory.\nIt will only enable performance optimizations in the lexer.")]),t._v(" "),t._m(37),t._v(" "),s("p",[t._v("Chevrotain treats /\\n|\\r\\n?/ as line terminators, but that is insufficient for some grammars\nTherefore it is possible to customize the definition of line terminators using the the "),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/4_6_0/interfaces/ilexerconfig.html#lineterminatorspattern",target:"_blank",rel:"noopener noreferrer"}},[t._v("lineTerminatorPattern option"),s("OutboundLink")],1),t._v("\nWhen doing so however it is also necessary to provide the "),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/4_6_0/interfaces/ilexerconfig.html#lineTerminatorCharacters",target:"_blank",rel:"noopener noreferrer"}},[t._v("lineTerminatorCharacters option"),s("OutboundLink")],1),t._v(".\nThis causes a bit of duplication and may be simplified in future versions.")]),t._v(" "),s("p",[t._v("Example:")]),t._v(" "),t._m(38)])},[function(){var t=this.$createElement,e=this._self._c||t;return e("h1",{attrs:{id:"resolving-lexer-errors"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#resolving-lexer-errors","aria-hidden":"true"}},[this._v("#")]),this._v(" Resolving Lexer Errors")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ul",[s("li",[s("strong",[t._v("Warnings")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#LINE_BREAKS"}},[t._v("No LINE_BREAKS Found.")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#IDENTIFY_TERMINATOR"}},[t._v("Unable to identify line terminator usage in pattern.")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#CUSTOM_LINE_BREAK"}},[t._v("A Custom Token Pattern should specify the <line_breaks> option.")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#REGEXP_PARSING"}},[t._v("Failed parsing < /.../ > Using the regexp-to-ast library.")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#UNICODE_OPTIMIZE"}},[t._v("The regexp unicode flag is not currently supported by the regexp-to-ast library.")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#COMPLEMENT"}},[t._v("Complement Sets cannot be automatically optimized.")])])])])])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ul",[s("li",[s("strong",[t._v("Errors")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#ANCHORS"}},[t._v("Unexpected RegExp Anchor Error.")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#UNREACHABLE"}},[t._v("Token Can Never Be Matched.")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#CUSTOM_OPTIMIZE"}},[t._v("TokenType <...> is using a custom token pattern without providing <char_start_hint> parameter")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#MISSING_LINE_TERM_CHARS"}},[t._v("Missing <lineTerminatorCharacters> property on the Lexer config.")])])])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h1",{attrs:{id:"warnings"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#warnings","aria-hidden":"true"}},[this._v("#")]),this._v(" Warnings")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"LINE_BREAKS"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#LINE_BREAKS","aria-hidden":"true"}},[this._v("#")]),this._v(" No LINE_BREAKS Found")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myTokens "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("IntegerLiteral"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringLiteral"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" WhiteSpace "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*, ... */")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("myTokens"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    positionTracking"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"onlyOffset"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" createToken "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" chevrotain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createToken\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Whitespace "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Whitespace"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/\\s+/")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// This is normally computed automatically...")]),t._v("\n    line_breaks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myTokens "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("IntegerLiteral"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringLiteral"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" WhiteSpace "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*, ... */")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("myTokens"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("li",[e("p",[this._v("Also note that multi-line tokens such as some types of comments and string literals tokens may contain\nline terminators.")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"IDENTIFY_TERMINATOR"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#IDENTIFY_TERMINATOR","aria-hidden":"true"}},[this._v("#")]),this._v(" Unable to identify line terminator usage in pattern")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("To resolve this warning, "),e("strong",[this._v("explicitly")]),this._v(" specify the line_breaks option in the offending Token Types:")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" MyToken "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MyToken"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/abc/")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    line_breaks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" MultiLineStringLiteral "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MultiLineStringLiteral"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/`[^`]*`/")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    line_breaks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"CUSTOM_LINE_BREAK"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#CUSTOM_LINE_BREAK","aria-hidden":"true"}},[this._v("#")]),this._v(" A Custom Token Pattern should specify the <line_breaks> option")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" MyCustomToken "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MyCustomToken"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" exec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" matchFunction "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    line_breaks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" MyCustomMultiLineToken "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MyCustomMultiLineToken"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" exec"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" matchFunction2 "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    line_breaks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"REGEXP_PARSING"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#REGEXP_PARSING","aria-hidden":"true"}},[this._v("#")]),this._v(" Failed parsing < /.../ > Using the regexp-to-ast library")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Integer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Integer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// lets assume that this pattern caused an error in regexp-to-ast")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[1-9]\\d*/")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// by explicitly providing the first possible characters of this pattern")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// the analysis by the regexp-to-ast library will be skipped")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// and the optimization can be enabled.")]),t._v("\n    start_chars_hint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"3"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"4"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"5"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"6"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"7"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"8"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"9"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"UNICODE_OPTIMIZE"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#UNICODE_OPTIMIZE","aria-hidden":"true"}},[this._v("#")]),this._v(" The regexp unicode flag is not currently supported by the regexp-to-ast library")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 'ðŸ’©' character")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PileOfPoo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// \\u{xxxxx} 32bit unicode escape can only be used with the /u flag enabled.")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/\\u{1F4A9}/u")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The 'ðŸ’©' character is represented by surrogate pairs: '\\uD83D\\uDCA9'")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// the start_chars_hint should only be provided the first of the pair.")]),t._v("\n    start_chars_hint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("55357")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Another way to "),e("strong",[this._v("work around")]),this._v(" the issue is to define the pattern as a string literal.\nAs that kind can be trivially optimized.\nThis is naturally only relevant for simple patterns.\nFor example:")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LCurley"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// note that the pattern is a string literal, not a regExp literal.")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"COMPLEMENT"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#COMPLEMENT","aria-hidden":"true"}},[this._v("#")]),this._v(" Complement Sets cannot be automatically optimized")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("When a TokenType pattern uses a regExp complement Set as a potential "),e("strong",[this._v("first")]),this._v(" character\nthe optimization is skipped as translating a complement set to a regular set requires too many cpu cycles\nduring the Lexer's initialization.")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("For example an XML Text is defined by "),e("strong",[this._v("everything")]),this._v(" except a closing tag.")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" XMLText "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"XMLText"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[^<&]+/")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("This means that there are "),e("strong",[this._v("65533")]),this._v(" (65535 - 2) possible starting charCodes\nFor an XMLText token.")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" hints "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("65535")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 38 is '<' and 60 is '&'")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("38")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        hints"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" XMLText "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"XMLText"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[^<&]+/")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    start_chars_hint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" hints\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h1",{attrs:{id:"errors"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#errors","aria-hidden":"true"}},[this._v("#")]),this._v(" Errors")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"ANCHORS"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ANCHORS","aria-hidden":"true"}},[this._v("#")]),this._v(" Unexpected RegExp Anchor Error")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" createToken "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" chevrotain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createToken\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Using createToken API")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Whitespace "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Integer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// invalid pattern using both anchors")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/^\\d+$/")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// will throw an error")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("semVer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"UNREACHABLE"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#UNREACHABLE","aria-hidden":"true"}},[this._v("#")]),this._v(" Token can never be matched")])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("This error means that A Token type can never be successfully matched as\na "),e("strong",[this._v("previous")]),this._v(" Token type in the lexer definition will "),e("strong",[this._v("always")]),this._v(" matched instead.\nThis happens because the default behavior of Chevrotain is to attempt to match\ntokens "),e("strong",[this._v("by the order")]),this._v(" described in the lexer definition.")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" ForKeyword "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ForKeyword"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/for/")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Identifier "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Identifier"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[a-zA-z]+/")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Will throw Token <ForKeyword> can never be matched...")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// Because the input "for" is also a valid identifier')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// and matching an identifier will be attempted first.")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Identifier"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ForKeyword"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("ul",[e("li",[this._v("Note that this validation is limited to simple patterns such as keywords\nThe more general case of any pattern being a strict subset of a preceding pattern\nwill require much more in depth RegExp analysis capabilities.")])])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Identifier is now listed as the last Token type.")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ForKeyword"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Identifier"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("p",[this._v("Note that the solution provided above will create a new problem.\nAny identifier "),e("strong",[this._v("starting with")]),this._v(' "for" will be lexed as '),e("strong",[this._v("two separate")]),this._v(" tokens,\na ForKeyword and an identifier. For example:")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ForKeyword"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Identifier"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// [")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//    {image:"for"}')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//    {image:"ward"}')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" tokensResult "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" myLexer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tokenize")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"forward"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"CUSTOM_OPTIMIZE"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#CUSTOM_OPTIMIZE","aria-hidden":"true"}},[this._v("#")]),this._v(" TokenType <...> is using a custom token pattern without providing <char_start_hint> parameter")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" IntegerToken "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"IntegerToken"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("exec")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" offset")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* ... */")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    start_chars_hint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"3"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"4"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"5"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"6"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"7"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"8"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"9"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"MISSING_LINE_TERM_CHARS"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#MISSING_LINE_TERM_CHARS","aria-hidden":"true"}},[this._v("#")]),this._v(" Missing <lineTerminatorCharacters> property on the Lexer config")])},function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// For our lexer only "\\n" is a counted as a line terminator')]),t._v("\n    lineTerminatorsPattern"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/\\n/")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// Duplicate information, "\\n".charCodeAt(0) === 10')]),t._v("\n    lineTerminatorCharacters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])}],!1,null,null,null);e.default=n.exports}}]);