(window.webpackJsonp=window.webpackJsonp||[]).push([[41],{403:function(t,a,e){"use strict";e.r(a);var s=e(43),n=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"resolving-lexer-errors"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#resolving-lexer-errors"}},[t._v("#")]),t._v(" Resolving Lexer Errors")]),t._v(" "),e("ul",[e("li",[e("strong",[t._v("Warnings")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"#LINE_BREAKS"}},[t._v("No LINE_BREAKS Found.")])]),t._v(" "),e("li",[e("a",{attrs:{href:"#IDENTIFY_TERMINATOR"}},[t._v("Unable to identify line terminator usage in pattern.")])]),t._v(" "),e("li",[e("a",{attrs:{href:"#CUSTOM_LINE_BREAK"}},[t._v("A Custom Token Pattern should specify the <line_breaks> option.")])]),t._v(" "),e("li",[e("a",{attrs:{href:"#REGEXP_PARSING"}},[t._v("Failed parsing < /.../ > Using the regexp-to-ast library.")])]),t._v(" "),e("li",[e("a",{attrs:{href:"#UNICODE_OPTIMIZE"}},[t._v("The regexp unicode flag is not currently supported by the regexp-to-ast library.")])]),t._v(" "),e("li",[e("a",{attrs:{href:"#COMPLEMENT"}},[t._v("Complement Sets cannot be automatically optimized.")])])])])]),t._v(" "),e("ul",[e("li",[e("strong",[t._v("Errors")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"#ANCHORS"}},[t._v("Unexpected RegExp Anchor Error.")])]),t._v(" "),e("li",[e("a",{attrs:{href:"#UNREACHABLE"}},[t._v("Token Can Never Be Matched.")])]),t._v(" "),e("li",[e("a",{attrs:{href:"#CUSTOM_OPTIMIZE"}},[t._v("TokenType <...> is using a custom token pattern without providing <char_start_hint> parameter")])]),t._v(" "),e("li",[e("a",{attrs:{href:"#MISSING_LINE_TERM_CHARS"}},[t._v("Missing <lineTerminatorCharacters> property on the Lexer config.")])])])])]),t._v(" "),e("h1",{attrs:{id:"warnings"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#warnings"}},[t._v("#")]),t._v(" Warnings")]),t._v(" "),e("h2",{attrs:{id:"LINE_BREAKS"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#LINE_BREAKS"}},[t._v("#")]),t._v(" No LINE_BREAKS Found")]),t._v(" "),e("p",[t._v("A Chevrotain Lexer will by default track the full position information for each token.\nThis includes line and column information.")]),t._v(" "),e("p",[t._v("In order to support this the Lexer must be aware of which Tokens may include line terminators.\nNormally this information can be computed automatically however in some cases Chevrotain needs some hints.")]),t._v(" "),e("p",[t._v("This warning means that the Lexer has been defined to track line and column information (perhaps by default).\nYet not a single one of the Token definitions passed to it was detected as possibly containing line terminators.")]),t._v(" "),e("p",[t._v("To resolve this choose one of the following:")]),t._v(" "),e("ol",[e("li",[e("p",[t._v("Disable the line and column position tracking using the "),e("a",{attrs:{href:"https://chevrotain.io/documentation/10_1_0/interfaces/ilexerconfig.html#positiontracking",target:"_blank",rel:"noopener noreferrer"}},[t._v("positionTracking"),e("OutboundLink")],1),t._v(" configuration option.")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myTokens "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("IntegerLiteral"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringLiteral"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" WhiteSpace "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*, ... */")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("myTokens"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  positionTracking"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"onlyOffset"')]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),e("li",[e("p",[t._v("Mark the Tokens which may include a line terminator with an explicit line_breaks flag.")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" createToken "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" chevrotain"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createToken\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Whitespace "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Whitespace"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/\\s+/")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// This is normally computed automatically...")]),t._v("\n  line_breaks"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myTokens "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("IntegerLiteral"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringLiteral"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" WhiteSpace "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*, ... */")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("myTokens"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("ul",[e("li",[e("p",[t._v("Note that the definition of what constitutes a line terminator is controlled by the\n"),e("a",{attrs:{href:"https://chevrotain.io/documentation/10_1_0/interfaces/ilexerconfig.html#lineTerminatorsPattern",target:"_blank",rel:"noopener noreferrer"}},[t._v("lineTerminatorsPattern"),e("OutboundLink")],1),t._v(" lexer configuration property.")])]),t._v(" "),e("li",[e("p",[t._v("Also note that multi-line tokens such as some types of comments and string literals tokens may contain\nline terminators.")])])])])]),t._v(" "),e("h2",{attrs:{id:"IDENTIFY_TERMINATOR"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#IDENTIFY_TERMINATOR"}},[t._v("#")]),t._v(" Unable to identify line terminator usage in pattern")]),t._v(" "),e("p",[t._v("A Chevrotain lexer must be aware which of the Token Types may match a line terminator.\nThis is required to compute the correct line and column position information.\nNormally Chevrotain can identify this information automatically using the "),e("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast library"),e("OutboundLink")],1),t._v(",\nhowever sometimes this logic fails. This is only a "),e("strong",[t._v("warning")]),t._v(" which will cause a small performance\nloss to the lexer and would "),e("strong",[t._v("not")]),t._v(" impact its correctness.")]),t._v(" "),e("p",[t._v("To resolve this warning, "),e("strong",[t._v("explicitly")]),t._v(" specify the line_breaks option in the offending Token Types:")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" MyToken "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MyToken"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/abc/")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  line_breaks"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" MultiLineStringLiteral "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MultiLineStringLiteral"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/`[^`]*`/")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  line_breaks"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Also please open an issue in the "),e("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast library"),e("OutboundLink")],1),t._v("\nso the root problem could be tracked and resolved.")]),t._v(" "),e("h2",{attrs:{id:"CUSTOM_LINE_BREAK"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#CUSTOM_LINE_BREAK"}},[t._v("#")]),t._v(" A Custom Token Pattern should specify the <line_breaks> option")]),t._v(" "),e("p",[t._v("A Chevrotain lexer must be aware which of the Token Types may match a line terminator.\nIt is not possible to do so automatically when using "),e("a",{attrs:{href:"https://chevrotain.io/docs/guide/custom_token_patterns.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("custom token patterns"),e("OutboundLink")],1),t._v(".\nThis means it is highly recommended to explicitly provide the line_breaks argument when creating\na TokenType:")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" MyCustomToken "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MyCustomToken"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" exec"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" matchFunction "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  line_breaks"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" MyCustomMultiLineToken "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"MyCustomMultiLineToken"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" exec"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" matchFunction2 "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  line_breaks"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("This is only a "),e("strong",[t._v("warning")]),t._v(' which will cause a small performance\nloss to the lexer and would not impact its correctness.\nIf no explicit <line_break> option is provided it would be implicitly treated as "true"\nfor '),e("a",{attrs:{href:"https://chevrotain.io/docs/guide/custom_token_patterns.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("custom token patterns"),e("OutboundLink")],1),t._v(".")]),t._v(" "),e("h2",{attrs:{id:"REGEXP_PARSING"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#REGEXP_PARSING"}},[t._v("#")]),t._v(" Failed parsing < /.../ > Using the regexp-to-ast library")]),t._v(" "),e("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matches\nusing the next "),e("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode"),e("OutboundLink")],1),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),e("strong",[t._v("every")]),t._v(" Token Type must be identified.")]),t._v(" "),e("p",[t._v("This analysis is implemented using the "),e("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast"),e("OutboundLink")],1),t._v(" library.\nWhich means this "),e("strong",[t._v("warning")]),t._v(" usually indicates a bug in the regexp-to-ast library.\nThe impact is only that the optimization described above would become disabled.\nLexing and Parsing will still work correctly, only slower...")]),t._v(" "),e("p",[t._v("Please open a bug for the "),e("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast"),e("OutboundLink")],1),t._v(" library.\nThis issue can be "),e("strong",[t._v("worked around")]),t._v(' by explicitly providing a "'),e("a",{attrs:{href:"https://chevrotain.io/documentation/10_1_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),e("OutboundLink")],1),t._v('" property.')]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Integer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Integer"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// lets assume that this pattern caused an error in regexp-to-ast")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[1-9]\\d*/")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// by explicitly providing the first possible characters of this pattern")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// the analysis by the regexp-to-ast library will be skipped")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// and the optimization can be enabled.")]),t._v("\n  start_chars_hint"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"3"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"4"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"5"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"6"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"7"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"8"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"9"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("h2",{attrs:{id:"UNICODE_OPTIMIZE"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#UNICODE_OPTIMIZE"}},[t._v("#")]),t._v(" The regexp unicode flag is not currently supported by the regexp-to-ast library")]),t._v(" "),e("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matches\nusing the next "),e("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode"),e("OutboundLink")],1),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),e("strong",[t._v("every")]),t._v(" TokenType must be identified.")]),t._v(" "),e("p",[t._v("This analysis is implemented using the "),e("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast"),e("OutboundLink")],1),t._v(" library.\nThis library currently does not support the "),e("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/unicode",target:"_blank",rel:"noopener noreferrer"}},[t._v("unicode regexp flag"),e("OutboundLink")],1),t._v("\nThe impact is that the optimization described above would become disabled.\nLexing and Parsing will still work correctly, just slower...")]),t._v(" "),e("p",[t._v("This issue can be "),e("strong",[t._v("worked around")]),t._v(' by explicitly providing a "'),e("a",{attrs:{href:"https://chevrotain.io/documentation/10_1_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),e("OutboundLink")],1),t._v('" property.')]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// '💩' character")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PileOfPoo"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// \\u{xxxxx} 32bit unicode escape can only be used with the /u flag enabled.")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/\\u{1F4A9}/u")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The '💩' character is represented by surrogate pairs: '\\uD83D\\uDCA9'")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// the start_chars_hint should only be provided the first of the pair.")]),t._v("\n  start_chars_hint"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("55357")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Another way to "),e("strong",[t._v("work around")]),t._v(" the issue is to define the pattern as a string literal.\nAs that kind can be trivially optimized.\nThis is naturally only relevant for simple patterns.\nFor example:")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"LCurley"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// note that the pattern is a string literal, not a regExp literal.")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{"')]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("h2",{attrs:{id:"COMPLEMENT"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#COMPLEMENT"}},[t._v("#")]),t._v(" Complement Sets cannot be automatically optimized")]),t._v(" "),e("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matches\nusing the next "),e("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode"),e("OutboundLink")],1),t._v(" about to be consumed.\nTo apply this optimization the first possible charCodes for "),e("strong",[t._v("every")]),t._v(" TokenType must be known in advance.")]),t._v(" "),e("p",[t._v("When a TokenType pattern uses a regExp complement set as a potential "),e("strong",[t._v("first")]),t._v(" character\nthe optimization is skipped as translating a complement set to a regular set is fairly costly\nduring the Lexer's initialization.")]),t._v(" "),e("p",[t._v("For example an XML Text is defined by "),e("strong",[t._v("everything")]),t._v(" except a closing tag.")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" XMLText "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"XMLText"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[^<&]+/")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("This means that there are "),e("strong",[t._v("65533")]),t._v(" (65535 - 2) possible starting charCodes\nFor an XMLText token.")]),t._v(" "),e("p",[t._v('If the use of these runtime optimizations is needed and the startup resources cost is acceptable\nIt is possible to enable the optimizations by explicitly providing a "'),e("a",{attrs:{href:"https://chevrotain.io/documentation/10_1_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),e("OutboundLink")],1),t._v('" property.\ne.g:')]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" hints "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" i "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("65535")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 38 is '<' and 60 is '&'")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("38")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" i "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    hints"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" XMLText "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"XMLText"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[^<&]+/")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  start_chars_hint"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" hints\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Please Note that filling such an array "),e("a",{attrs:{href:"https://jsperf.com/fill-16-bits",target:"_blank",rel:"noopener noreferrer"}},[t._v("can take over 1ms"),e("OutboundLink")],1),t._v(" on a modern machine.\nSo if you are only parsing small inputs and/or starting a new process for each\nparser invocation the added initialization cost may be counter productive.")]),t._v(" "),e("p",[t._v("Another solution to this problem is to re-define the Token pattern without using a complement.\nFor example: the XMLText pattern above could be re-defined as:")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" XMLText "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"XMLText"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Equivalent to: /[^<&]+/ but a-lot less clear :(")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Note that:")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//   - "\\u0026" === "&"')]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//   - "\\u003C" === "<"')]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[\\u0000-\\u0025\\u0027-\\u003B\\u003D-\\uFFFF]+/")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Note that internally Chevrotain avoids creating a 16bits large data structure\nso this method would be the most optimized both in terms of runtime and initialization time.")]),t._v(" "),e("h1",{attrs:{id:"errors"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#errors"}},[t._v("#")]),t._v(" Errors")]),t._v(" "),e("h2",{attrs:{id:"ANCHORS"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ANCHORS"}},[t._v("#")]),t._v(" Unexpected RegExp Anchor Error")]),t._v(" "),e("p",[t._v("A Token RegExp pattern used in a chevrotain lexer may not use the start/end of input anchors ('$' and '^').")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" createToken "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" chevrotain"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createToken\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Using createToken API")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Whitespace "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Integer"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// invalid pattern using both anchors")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/^\\d+$/")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// will throw an error")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("semVer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("To resolve this simply avoid using anchors in your Token Types patterns.")]),t._v(" "),e("h2",{attrs:{id:"UNREACHABLE"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#UNREACHABLE"}},[t._v("#")]),t._v(" Token can never be matched")]),t._v(" "),e("p",[t._v("This error means that A Token type can never be successfully matched as\na "),e("strong",[t._v("previous")]),t._v(" Token type in the lexer definition will "),e("strong",[t._v("always")]),t._v(" matched instead.\nThis happens because the default behavior of Chevrotain is to attempt to match\ntokens "),e("strong",[t._v("by the order")]),t._v(" described in the lexer definition.")]),t._v(" "),e("p",[t._v("For example:")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" ForKeyword "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ForKeyword"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/for/")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Identifier "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Identifier"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/[a-zA-z]+/")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Will throw Token <ForKeyword> can never be matched...")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// Because the input "for" is also a valid identifier')]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// and matching an identifier will be attempted first.")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Identifier"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ForKeyword"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("ul",[e("li",[t._v("Note that this validation is limited to simple patterns such as keywords\nThe more general case of any pattern being a strict subset of a preceding pattern\nwill require much more in depth RegExp analysis capabilities.")])]),t._v(" "),e("p",[t._v("To resolve this simply re-arrange the order of Token types in the lexer\ndefinition such that the more specific Token types will be listed first.")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Identifier is now listed as the last Token type.")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ForKeyword"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Identifier"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("Note that the solution provided above will create a new problem.\nAny identifier "),e("strong",[t._v("starting with")]),t._v(' "for" will be lexed as '),e("strong",[t._v("two separate")]),t._v(" tokens,\na ForKeyword and an identifier. For example:")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ForKeyword"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Identifier"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// [")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//    {image:"for"}')]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//    {image:"ward"}')]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ]")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" tokensResult "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" myLexer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("tokenize")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"forward"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("To resolve this second problem see how to prefer the "),e("strong",[t._v("longest match")]),t._v("\nas demonstrated in the "),e("a",{attrs:{href:"https://github.com/chevrotain/chevrotain/blob/master/examples/lexer/keywords_vs_identifiers/keywords_vs_identifiers.js",target:"_blank",rel:"noopener noreferrer"}},[t._v("keywords vs identifiers example"),e("OutboundLink")],1)]),t._v(" "),e("h2",{attrs:{id:"CUSTOM_OPTIMIZE"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#CUSTOM_OPTIMIZE"}},[t._v("#")]),t._v(" TokenType <...> is using a custom token pattern without providing <char_start_hint> parameter")]),t._v(" "),e("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matches\nusing the next "),e("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode"),e("OutboundLink")],1),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),e("strong",[t._v("every")]),t._v(" TokenType must be identified.")]),t._v(" "),e("p",[t._v("This information cannot be automatically computed for "),e("a",{attrs:{href:"https://chevrotain.io/docs/guide/custom_token_patterns.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("custom token patterns"),e("OutboundLink")],1),t._v("\nand "),e("strong",[t._v("should")]),t._v(' therefore be explicitly provided using the "'),e("a",{attrs:{href:"https://chevrotain.io/documentation/10_1_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),e("OutboundLink")],1),t._v('" property.')]),t._v(" "),e("p",[t._v("For example:")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" IntegerToken "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("createToken")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"IntegerToken"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  pattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("exec")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("text"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" offset")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* ... */")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  start_chars_hint"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"3"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"4"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"5"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"6"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"7"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"8"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"9"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v('Providing the "'),e("a",{attrs:{href:"https://chevrotain.io/documentation/10_1_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint"),e("OutboundLink")],1),t._v('" property is '),e("strong",[t._v("not")]),t._v(" mandatory.\nIt will only enable performance optimizations in the lexer.")]),t._v(" "),e("h2",{attrs:{id:"MISSING_LINE_TERM_CHARS"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#MISSING_LINE_TERM_CHARS"}},[t._v("#")]),t._v(" Missing <lineTerminatorCharacters> property on the Lexer config")]),t._v(" "),e("p",[t._v("Chevrotain treats "),e("code",[t._v("/\\n|\\r\\n?/")]),t._v(" as line terminators, but that is insufficient for some grammars.\nTherefore, it is possible to customize the definition of line terminators using the "),e("a",{attrs:{href:"https://chevrotain.io/documentation/10_1_0/interfaces/ilexerconfig.html#lineterminatorspattern",target:"_blank",rel:"noopener noreferrer"}},[t._v("lineTerminatorPattern option"),e("OutboundLink")],1),t._v(".\nWhen doing so, however, it is also necessary to provide the "),e("a",{attrs:{href:"https://chevrotain.io/documentation/10_1_0/interfaces/ilexerconfig.html#lineTerminatorCharacters",target:"_blank",rel:"noopener noreferrer"}},[t._v("lineTerminatorCharacters option"),e("OutboundLink")],1),t._v(".\nThis causes a bit of duplication and may be simplified in future versions.")]),t._v(" "),e("p",[t._v("Example:")]),t._v(" "),e("div",{staticClass:"language-javascript extra-class"},[e("pre",{pre:!0,attrs:{class:"language-javascript"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("chevrotain"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// For our lexer only "\\n" is a counted as a line terminator')]),t._v("\n  lineTerminatorsPattern"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token regex"}},[t._v("/\\n/")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// Duplicate information, "\\n".charCodeAt(0) === 10')]),t._v("\n  lineTerminatorCharacters"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);